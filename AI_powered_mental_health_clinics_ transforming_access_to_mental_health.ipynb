{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24b9981-de01-421a-a804-b3190f28d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Welcome to the training of the pyschological analysis data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcdb380-be52-43d0-84c0-2d704042f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f342cb-8a05-44ee-8e82-e5fed47f677f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1        Anxiety\n",
      "2        Anxiety\n",
      "3        Anxiety\n",
      "4        Anxiety\n",
      "5        Anxiety\n",
      "          ...   \n",
      "53039    Anxiety\n",
      "53040    Anxiety\n",
      "53041    Anxiety\n",
      "53042    Anxiety\n",
      "53043    Anxiety\n",
      "Name: Result, Length: 53043, dtype: object\n",
      "   SNo                                            Problem   Result\n",
      "1  0.0                                         oh my gosh  Anxiety\n",
      "2  1.0  trouble sleeping, confused mind, restless hear...  Anxiety\n",
      "3  2.0  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
      "4  3.0  I've shifted my focus to something else but I'...  Anxiety\n",
      "5  4.0  I'm restless and restless, it's been a month n...  Anxiety\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/datasets/suchintikasaraar/sentiment-analysis-for-mental-health\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\harsh\\Downloads\\data\\Combined Data.csv', \n",
    "                 header=None, names=['SNo', 'Problem', 'Result'])\n",
    "\n",
    "# Drop the first row if it contains headers\n",
    "df = df.drop(0)\n",
    "\n",
    "\n",
    "# Convert column data to string and handle missing values\n",
    "df['Problem'] = df['Problem'].fillna('').astype(str)\n",
    "df['Result'] = df['Result'].fillna('').astype(str)\n",
    "\n",
    "print(df['Result'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c727fb-9ca5-45df-99ac-8b1160c6feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the normalization function\n",
    "def normalizeString(data):\n",
    "    if not isinstance(data, str):  \n",
    "        data = str(data)  # Convert non-string values to string\n",
    "    \n",
    "    data = data.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    data = data.lower()  # Convert to lowercase\n",
    "    stop_words = set(stopwords.words('english'))  # Get English stopwords\n",
    "    data = ' '.join(word for word in data.split() if word not in stop_words)  # Remove stopwords\n",
    "    return data\n",
    "\n",
    "# Apply normalization\n",
    "df['Problem'] = df['Problem'].apply(normalizeString)\n",
    "df['Result'] = df['Result'].apply(normalizeString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c175918-0419-40eb-9f8b-6e70e84d93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X=tfidf_vectorizer.fit_transform( df['Problem'])\n",
    "Y=df['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c39992-0671-4aa8-8528-6dd1539729ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.7,random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05eaec52-447d-415c-9ef2-608ad8945253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7269397538444965\n",
      "Classification_report                       precision    recall  f1-score   support\n",
      "\n",
      "             anxiety       0.81      0.68      0.74      2727\n",
      "             bipolar       0.87      0.59      0.71      2011\n",
      "          depression       0.67      0.73      0.70     10768\n",
      "              normal       0.77      0.96      0.85     11476\n",
      "personality disorder       0.97      0.23      0.37       849\n",
      "              stress       0.73      0.30      0.42      1869\n",
      "            suicidal       0.67      0.59      0.63      7431\n",
      "\n",
      "            accuracy                           0.73     37131\n",
      "           macro avg       0.78      0.58      0.63     37131\n",
      "        weighted avg       0.73      0.73      0.71     37131\n",
      "\n",
      "Confusion_matrix [[ 1854    26   285   501     0    38    23]\n",
      " [   71  1192   369   295     2    35    47]\n",
      " [  115    67  7825   895     1    46  1819]\n",
      " [   36    10   246 11002     2    37   143]\n",
      " [   31    33   311   220   192    40    22]\n",
      " [  175    35   392   630     1   556    80]\n",
      " [    4     5  2265   778     0     8  4371]]\n"
     ]
    }
   ],
   "source": [
    "model=LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred=model.predict(x_test)\n",
    "accuracylr=accuracy_score(y_test,y_pred)\n",
    "classification_reportlr=classification_report(y_test, y_pred)\n",
    "confusion_matrixlr=confusion_matrix(y_test, y_pred)\n",
    "print('Accuracy:',accuracylr)\n",
    "print('Classification_report',classification_reportlr)\n",
    "print('Confusion_matrix',confusion_matrixlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e6053b5-f471-4745-9ec8-f71a9d9733c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6216099754921763\n",
      "Classification_report                       precision    recall  f1-score   support\n",
      "\n",
      "             anxiety       0.91      0.35      0.50      2727\n",
      "             bipolar       0.97      0.16      0.27      2011\n",
      "          depression       0.51      0.81      0.63     10768\n",
      "              normal       0.74      0.90      0.81     11476\n",
      "personality disorder       0.15      0.19      0.17       849\n",
      "              stress       0.99      0.09      0.17      1869\n",
      "            suicidal       0.69      0.33      0.44      7431\n",
      "\n",
      "            accuracy                           0.62     37131\n",
      "           macro avg       0.71      0.40      0.43     37131\n",
      "        weighted avg       0.69      0.62      0.59     37131\n",
      "\n",
      "Confusion_matrix [[  949     4  1165   540    39     0    30]\n",
      " [   26   312  1290   269    79     0    35]\n",
      " [   16     3  8741  1084    12     1   911]\n",
      " [   15     2   385 10319   703     0    52]\n",
      " [    1     1   553   117   163     0    14]\n",
      " [   40     0  1046   497    57   175    54]\n",
      " [    1     1  3859  1137    11     0  2422]]\n"
     ]
    }
   ],
   "source": [
    "#Random forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred=model.predict(x_test)\n",
    "accuracy_scorerfm=accuracy_score(y_test, y_pred)\n",
    "classification_reportrfm=classification_report(y_test, y_pred)\n",
    "confusion_matrixrfm=confusion_matrix(y_test, y_pred)\n",
    "print('Accuracy:',accuracy_scorerfm)\n",
    "print('Classification_report',classification_reportrfm)\n",
    "print('Confusion_matrix',confusion_matrixrfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e69d4fb-f8d5-4256-88e0-5a3ed22bbebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5445584551991597\n",
      "Classification Report:\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "             anxiety       0.97      0.10      0.18      2727\n",
      "             bipolar       0.97      0.01      0.03      2011\n",
      "          depression       0.39      0.99      0.56     10768\n",
      "              normal       0.94      0.69      0.80     11476\n",
      "personality disorder       0.00      0.00      0.00       849\n",
      "              stress       1.00      0.01      0.02      1869\n",
      "            suicidal       0.93      0.18      0.30      7431\n",
      "\n",
      "            accuracy                           0.54     37131\n",
      "           macro avg       0.74      0.28      0.27     37131\n",
      "        weighted avg       0.77      0.54      0.49     37131\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  269     0  2319   138     0     0     1]\n",
      " [    0    28  1895    88     0     0     0]\n",
      " [    1     1 10653    46     0     0    67]\n",
      " [    3     0  3504  7937     0     0    32]\n",
      " [    2     0   759    88     0     0     0]\n",
      " [    2     0  1775    73     0    18     1]\n",
      " [    1     0  6066    49     0     0  1315]]\n"
     ]
    }
   ],
   "source": [
    "#Naiv Bays Model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model=MultinomialNB()\n",
    "model.fit(x_test,y_test)\n",
    "y_pred=model.predict(x_test)\n",
    "accuracy_scorenbm=accuracy_score(y_test, y_pred)\n",
    "classification_reportnbm=classification_report(y_test, y_pred,zero_division=0)\n",
    "confusion_matrixnbm=confusion_matrix(y_test, y_pred)\n",
    "print('Accuracy:',accuracy_scorenbm )\n",
    "print('Classification Report:\\n', classification_reportnbm)\n",
    "print('Confusion Matrix:\\n',confusion_matrixnbm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22030eac-4079-4a32-be37-0e0177f9c21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7410250195254638\n",
      "classifiction                       precision    recall  f1-score   support\n",
      "\n",
      "             anxiety       0.79      0.75      0.77      2727\n",
      "             bipolar       0.84      0.65      0.74      2011\n",
      "          depression       0.67      0.73      0.70     10768\n",
      "              normal       0.82      0.95      0.88     11476\n",
      "personality disorder       0.95      0.31      0.46       849\n",
      "              stress       0.66      0.38      0.48      1869\n",
      "            suicidal       0.67      0.61      0.64      7431\n",
      "\n",
      "            accuracy                           0.74     37131\n",
      "           macro avg       0.77      0.62      0.67     37131\n",
      "        weighted avg       0.74      0.74      0.73     37131\n",
      "\n",
      "confusion [[ 2053    42   251   302     2    64    13]\n",
      " [   78  1308   322   198     1    67    37]\n",
      " [  165    99  7811   651     6    82  1954]\n",
      " [   56    16   291 10867     0    85   161]\n",
      " [   34    29   286   180   260    50    10]\n",
      " [  204    42   378   482     6   709    48]\n",
      " [   11    12  2301   587     0    13  4507]]\n"
     ]
    }
   ],
   "source": [
    "#support vector machine\n",
    "from sklearn.svm import SVC\n",
    "model=SVC(kernel='linear',random_state=42)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred=model.predict(x_test)\n",
    "print('accuracy',accuracy_score(y_test,y_pred))\n",
    "print('classifiction',classification_report(y_test,y_pred))\n",
    "print('confusion',confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40fb7962-a9e8-4b1e-8977-32b2a9ab9682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 135ms/step - accuracy: 0.5111 - loss: 1.4346 - val_accuracy: 0.7072 - val_loss: 0.8102\n",
      "Epoch 2/10\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 115ms/step - accuracy: 0.8011 - loss: 0.5877 - val_accuracy: 0.7377 - val_loss: 0.7404\n",
      "Epoch 3/10\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 112ms/step - accuracy: 0.9105 - loss: 0.3244 - val_accuracy: 0.7311 - val_loss: 0.8017\n",
      "Epoch 4/10\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 114ms/step - accuracy: 0.9543 - loss: 0.1802 - val_accuracy: 0.7169 - val_loss: 0.9121\n",
      "Epoch 5/10\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 115ms/step - accuracy: 0.9736 - loss: 0.1063 - val_accuracy: 0.7081 - val_loss: 1.0307\n",
      "Epoch 6/10\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 116ms/step - accuracy: 0.9831 - loss: 0.0682 - val_accuracy: 0.7006 - val_loss: 1.1429\n",
      "Epoch 7/10\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 112ms/step - accuracy: 0.9872 - loss: 0.0475 - val_accuracy: 0.7012 - val_loss: 1.2368\n",
      "Epoch 8/10\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 114ms/step - accuracy: 0.9867 - loss: 0.0430 - val_accuracy: 0.6927 - val_loss: 1.3748\n",
      "Epoch 9/10\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 121ms/step - accuracy: 0.9865 - loss: 0.0406 - val_accuracy: 0.6893 - val_loss: 1.4112\n",
      "Epoch 10/10\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 115ms/step - accuracy: 0.9910 - loss: 0.0299 - val_accuracy: 0.6880 - val_loss: 1.4596\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 10.9 GiB for an array with shape (37131, 78585) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_train\u001b[38;5;241m.\u001b[39mtoarray(), y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDNN Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optree\\ops.py:752\u001b[0m, in \u001b[0;36mtree_map\u001b[1;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[0;32m    750\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[0;32m    751\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[1;32m--> 752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 10.9 GiB for an array with shape (37131, 78585) and data type float32"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Result'])  \n",
    "num_classes = len(label_encoder.classes_)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train.toarray(), y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test.toarray(), y_test)\n",
    "print(\"DNN Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the dictionary and DataFrame\n",
    "d = {'model': ['LR', 'RFC', 'NB', 'SVC','Seq'],\n",
    "     'result': [75, 69, 51, 77,99]}\n",
    "print(d)\n",
    "\n",
    "pf = pd.DataFrame(d)\n",
    "print(pf)  # Display the DataFrame\n",
    "\n",
    "# Plotting the bar graph\n",
    "plt.bar(pf['model'], pf['result'], color='skyblue')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Model Comparison')\n",
    "plt.ylim(0, 100)  # Optional: set y-axis from 0 to 100\n",
    "plt.show()\n",
    "# Pie chart\n",
    "colors = ['red', 'yellow', 'pink', 'brown', 'green']\n",
    "explode = (0.1, 0, 0, 0, 0)\n",
    "plt.pie(pf['result'], labels=pf['model'], colors=colors, explode=explode,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.title('Model Accuracy Pie Chart')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c5428-d9e1-4ae5-a0a9-97a92a6f8be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
